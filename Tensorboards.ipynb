{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3387c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c7469d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.9.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b342ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000\n",
    "# 80% of the data is for training.\n",
    "train_pct = 0.8\n",
    "\n",
    "train_size = int(data_size * train_pct)\n",
    "\n",
    "# Create some input data between -1 and 1 and randomize it.\n",
    "x = np.linspace(-1, 1, data_size)\n",
    "np.random.shuffle(x)\n",
    "\n",
    "# Generate the output data.\n",
    "# y = 0.5x + 2 + noise\n",
    "y = 0.5 * x + 2 + np.random.normal(0, 0.05, (data_size, ))\n",
    "\n",
    "# Split into test and train pairs.\n",
    "x_train, y_train = x[:train_size], y[:train_size]\n",
    "x_test, y_test = x[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a71f91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ... With default parameters, this takes less than 10 seconds.\n",
      "Average test loss:  0.04285089503508061\n"
     ]
    }
   ],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, input_dim=1),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='mse', # keras.losses.mean_squared_error\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.2),\n",
    ")\n",
    "\n",
    "print(\"Training ... With default parameters, this takes less than 10 seconds.\")\n",
    "training_history = model.fit(\n",
    "    x_train, # input\n",
    "    y_train, # output\n",
    "    batch_size=train_size,\n",
    "    verbose=0, # Suppress chatty output; use Tensorboard instead\n",
    "    epochs=100,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[tensorboard_callback],\n",
    ")\n",
    "\n",
    "print(\"Average test loss: \", np.average(training_history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a51af831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f727b46c78fbd7a0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f727b46c78fbd7a0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eabdd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 147ms/step\n",
      "[[31.782286 ]\n",
      " [14.408746 ]\n",
      " [ 2.9918473]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([60, 25, 2]))\n",
    "# True values to compare predictions against: \n",
    "# [[32.0]\n",
    "#  [14.5]\n",
    "#  [ 3.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "613ce53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "  \"\"\"\n",
    "  Returns a custom learning rate that decreases as epochs progress.\n",
    "  \"\"\"\n",
    "  learning_rate = 0.2\n",
    "  if epoch > 10:\n",
    "    learning_rate = 0.02\n",
    "  if epoch > 20:\n",
    "    learning_rate = 0.01\n",
    "  if epoch > 50:\n",
    "    learning_rate = 0.005\n",
    "\n",
    "  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "  return learning_rate\n",
    "\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, input_dim=1),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='mse', # keras.losses.mean_squared_error\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    ")\n",
    "\n",
    "training_history = model.fit(\n",
    "    x_train, # input\n",
    "    y_train, # output\n",
    "    batch_size=train_size,\n",
    "    verbose=0, # Suppress chatty output; use Tensorboard instead\n",
    "    epochs=100,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[tensorboard_callback, lr_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c23cca06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17436), started 0:00:07 ago. (Use '!kill 17436' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5bbd3a43c95b6cf3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5bbd3a43c95b6cf3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e93b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 155ms/step\n",
      "[[31.765066]\n",
      " [14.401572]\n",
      " [ 2.991277]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([60, 25, 2]))\n",
    "# True values to compare predictions against: \n",
    "# [[32.0]\n",
    "#  [14.5]\n",
    "#  [ 3.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d656ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d824a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'logs/batch_level/' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/train'\n",
    "train_writer = tf.summary.create_file_writer(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21daf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, model):\n",
    "    super().__init__()\n",
    "    self.model = model\n",
    "\n",
    "  def train_step(self, data):\n",
    "    x, y = data\n",
    "    with tf.GradientTape() as tape:\n",
    "      y_pred = self.model(x, training=True)\n",
    "      loss = self.compiled_loss(y, y_pred)\n",
    "      mse = tf.keras.losses.mean_squared_error(y, K.max(y_pred, axis=-1))\n",
    "    self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n",
    "    with train_writer.as_default(step=self._train_counter):\n",
    "      tf.summary.scalar('batch_loss', loss)\n",
    "      tf.summary.scalar('batch_mse', mse)\n",
    "    return self.compute_metrics(x, y, y_pred, None)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.model(x)\n",
    "    return x\n",
    "\n",
    "# Adds custom batch-level metrics to our previous Functional API model\n",
    "model = MyModel(create_model())\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9906140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "120/120 [==============================] - 4s 26ms/step - loss: 0.4383 - accuracy: 0.8760 - val_loss: 0.2085 - val_accuracy: 0.9399\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1882 - accuracy: 0.9462 - val_loss: 0.1395 - val_accuracy: 0.9595\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1359 - accuracy: 0.9618 - val_loss: 0.1125 - val_accuracy: 0.9660\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1058 - accuracy: 0.9696 - val_loss: 0.0971 - val_accuracy: 0.9707\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0846 - accuracy: 0.9759 - val_loss: 0.0830 - val_accuracy: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22cf3a79dc0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train,\n",
    "          epochs=5,\n",
    "          batch_size=500, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9e05ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'logs/batch_avg/' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/train'\n",
    "train_writer = tf.summary.create_file_writer(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e5072ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss = tf.keras.metrics.Mean('batch_loss', dtype=tf.float32)\n",
    "batch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('batch_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "979d7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, model):\n",
    "    super().__init__()\n",
    "    self.model = model\n",
    "\n",
    "  def train_step(self, data):\n",
    "    x, y = data\n",
    "    with tf.GradientTape() as tape:\n",
    "      y_pred = self.model(x, training=True)\n",
    "      loss = self.compiled_loss(y, y_pred)\n",
    "    self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n",
    "    batch_loss(loss)\n",
    "    batch_accuracy(y, y_pred)\n",
    "    with train_writer.as_default(step=self._train_counter):\n",
    "      tf.summary.scalar('batch_loss', batch_loss.result())\n",
    "      tf.summary.scalar('batch_accuracy', batch_accuracy.result())\n",
    "    return self.compute_metrics(x, y, y_pred, None)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.model(x)\n",
    "    return x\n",
    "\n",
    "# Adds custom batch-level metrics to our previous Functional API model\n",
    "model = MyModel(create_model())\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93b7140d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "120/120 [==============================] - 5s 31ms/step - loss: 0.4255 - accuracy: 0.8812 - val_loss: 0.2100 - val_accuracy: 0.9411\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1871 - accuracy: 0.9470 - val_loss: 0.1441 - val_accuracy: 0.9595\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.1334 - accuracy: 0.9618 - val_loss: 0.1134 - val_accuracy: 0.9677\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1036 - accuracy: 0.9707 - val_loss: 0.0932 - val_accuracy: 0.9722\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.0855 - accuracy: 0.9757 - val_loss: 0.0830 - val_accuracy: 0.9742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22cf63ac730>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train,\n",
    "          epochs=5,\n",
    "          batch_size=500, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d076d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
